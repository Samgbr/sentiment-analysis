{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import sys\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>steve carell stars person relate to sort of da...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>found enjoyable muppets movie felt light heart...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>altogether bad start program slap face real la...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>saw film tonight nyc landmark sunshine did not...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>much like japanese movies one did not cut it m...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  steve carell stars person relate to sort of da...          1\n",
       "1  found enjoyable muppets movie felt light heart...          1\n",
       "2  altogether bad start program slap face real la...          0\n",
       "3  saw film tonight nyc landmark sunshine did not...          1\n",
       "4  much like japanese movies one did not cut it m...          0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('CleanIMDB_train.csv') # Windows single-byte character encoding\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5000 entries, 0 to 4999\n",
      "Data columns (total 2 columns):\n",
      "review       5000 non-null object\n",
      "sentiment    5000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 78.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total dataset length: 5000\n"
     ]
    }
   ],
   "source": [
    "print('Total dataset length: %d' %(len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data to train and test\n",
    "X = df.iloc[:, 0].values\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data count vector total number of features: 37996\n"
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer()\n",
    "# vectorize the data set\n",
    "X_matrix = cvec.fit_transform(X)\n",
    "print('Train data count vector total number of features: %d' %(len(cvec.get_feature_names())))\n",
    "X_matrix.shape\n",
    "X_matrix_ = X_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_matrix_,y,test_size=0.20, random_state=42)\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training entries length: 4000\n",
      "Negative training entries account for percent: 51.125000\n",
      "Positive training entries account for percent: 51.125000\n",
      "Total test entries length: 1000\n",
      "Negative test entries account for percent: 51.900000\n",
      "Positive test entries account for percent: 48.100000\n"
     ]
    }
   ],
   "source": [
    "print('Total training entries length: %d' %(len(X_train)))\n",
    "print('Negative training entries account for percent: %f' %(Counter(y_train)[0]/len(y_train)*100))\n",
    "print('Positive training entries account for percent: %f' %(Counter(y_train)[0]/len(y_train)*100))\n",
    "print('Total test entries length: %d' %(len(y_test)))\n",
    "print('Negative test entries account for percent: %f' %(Counter(y_test)[0]/len(y_test)*100))\n",
    "print('Positive test entries account for percent: %f' %(Counter(y_test)[1]/len(y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the train to train and validation - Holdout Method\n",
    "X_train_, X_val,y_train_,y_val = train_test_split(X_train,y_train,test_size=0.20, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training entries after validation split: 3200\n",
      "Negative train entries after val split account for percent: 51.156250\n",
      "Positive train entries after val split account for percent: 48.843750\n",
      "Total validation entries after train split: 800\n",
      "Negative validation entries after val split account for percent: 51.000000\n",
      "Positive validation entries after val split account for percent: 49.000000\n"
     ]
    }
   ],
   "source": [
    "print(\"Total training entries after validation split: %d\" %(len(X_train_)))\n",
    "print('Negative train entries after val split account for percent: %f' %(Counter(y_train_)[0]/len(y_train_)*100))\n",
    "print('Positive train entries after val split account for percent: %f' %(Counter(y_train_)[1]/len(y_train_)*100))\n",
    "print(\"Total validation entries after train split: %d\" %(len(X_val)))\n",
    "print('Negative validation entries after val split account for percent: %f' %(Counter(y_val)[0]/len(y_val)*100))\n",
    "print('Positive validation entries after val split account for percent: %f' %(Counter(y_val)[1]/len(y_val)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "log_model = LogisticRegression(C=1.0, random_state=None, solver='liblinear', penalty='l2')\n",
    "# Fit the train dataset with LR\n",
    "log_model = log_model.fit(X=X_train_, y=y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation dataset logistics regression: 0.843750\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_val)\n",
    "print('Accuracy validation dataset logistics regression: %f' % accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[344,  64],\n",
       "       [ 61, 331]], dtype=int64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.84      0.85       408\n",
      "          1       0.84      0.84      0.84       392\n",
      "\n",
      "avg / total       0.84      0.84      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_model = SVC(C=100.0, kernel='rbf', random_state=None, gamma='auto')\n",
    "svm_model = svm_model.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation dataset SVM: 0.841250\n"
     ]
    }
   ],
   "source": [
    "y_pred = svm_model.predict(X_val)\n",
    "print('Accuracy validation dataset SVM: %f' % accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[408,   0],\n",
       "       [ 23, 369]], dtype=int64)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      1.00      0.97       408\n",
      "          1       1.00      0.94      0.97       392\n",
      "\n",
      "avg / total       0.97      0.97      0.97       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Bernoulli\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.815"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive Bayes Bernoulli\n",
    "bnb = BernoulliNB(binarize=0.0)\n",
    "bnb.fit(X_train_, y_train_)\n",
    "print('Naive Bayes Bernoulli')\n",
    "bnb.score(X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation dataset Naive Bayes(Multinomonal): 0.841250\n"
     ]
    }
   ],
   "source": [
    "# Multinominal Naive Bayes\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(X_train_, y_train_)\n",
    "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)\n",
    "y_pred = mnb.predict(X_val)\n",
    "print('Accuracy validation dataset Naive Bayes(Multinomonal): %f' % accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[363,  45],\n",
       "       [ 82, 310]], dtype=int64)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.89      0.85       408\n",
      "          1       0.87      0.79      0.83       392\n",
      "\n",
      "avg / total       0.84      0.84      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', max_iter=1000, n_iter=None,\n",
       "       n_jobs=1, penalty='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=0.001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = linear_model.SGDClassifier(max_iter=1000, tol=1e-3)\n",
    "clf.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation dataset AdalineSDG: 0.825000\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy validation dataset AdalineSDG: %f' % accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[350,  58],\n",
       "       [ 82, 310]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.86      0.83       408\n",
      "          1       0.84      0.79      0.82       392\n",
      "\n",
      "avg / total       0.83      0.82      0.82       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      max_iter=None, n_iter=None, n_jobs=1, penalty=None, random_state=0,\n",
       "      shuffle=True, tol=0.001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = Perceptron(tol=1e-3, random_state=0)\n",
    "clf.fit(X_train_, y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy validation dataset Perceptron: 0.836250\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy validation dataset Perceptron: %f' % accuracy_score(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[344,  64],\n",
       "       [ 67, 325]], dtype=int64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_val, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.84      0.84       408\n",
      "          1       0.84      0.83      0.83       392\n",
      "\n",
      "avg / total       0.84      0.84      0.84       800\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
       "           weights='uniform')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors = 5)\n",
    "knn.fit(X_train_,y_train_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.predict(X_val)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.585"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy test dataset logistics regression: 0.855000\n"
     ]
    }
   ],
   "source": [
    "y_pred = log_model.predict(X_test)\n",
    "print('Accuracy test dataset logistics regression: %f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
